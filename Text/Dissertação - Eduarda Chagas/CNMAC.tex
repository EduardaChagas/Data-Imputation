\documentclass[a4,11pt]{pssbmac}
\usepackage[english]{babel}   
\usepackage[utf8]{inputenc} 

\usepackage{graphics}
\usepackage{subfigure}
\usepackage{graphicx}
\usepackage[centertags]{amsmath}
\usepackage{indentfirst,amsfonts,amssymb,amsthm,newlfont}
\usepackage{bm,bbm}
\usepackage{longtable}
\usepackage{cite}
\usepackage[usenames,dvipsnames]{color}
\usepackage{booktabs}
\usepackage[binary-units]{siunitx}
\usepackage{multicol,multirow}
\usepackage{undertilde}
\usepackage{hyperref}

\DeclareSIUnit{\minusalphapercent}{(1-\alpha)\%}
\DeclareSIUnit{\alphapercent}{\alpha\%}

\begin{document}
	
	%********************************************************
	\title{Contributions to the Study of Time Series and Images with the Entropy-Complexity Plane}
	
	\author{
		{\large Eduarda T. C. Chagas}\thanks{eduarda.chagas@dcc.ufmg.br}\\
		{\small Departamento de Ci\^encia da Computa\c c\~ao, Universidade Federal de Minas Gerais, Brazil} \\
		{\large Alejandro C. Frery}\thanks{alejandro.frery@vuw.ac.nz} \\
		{\small School of Mathematics and Statistics, Victoria University of Wellington, New Zealand} \\
		{\large Heitor S. Ramos}\thanks{ramosh@dcc.ufmg.br} \\
		{\small Departamento de Ci\^encia da Computa\c c\~ao, Universidade Federal de Minas Gerais, Brazil} \\
	}
	
	\criartitulo
	
	\begin{abstract}
		{\bf Abstract}. In the context of non-parametric analysis of time series, the use of ordinal patterns combined with descriptors of information theory proved to have high power in characterizing processes underlying the data dynamics.
		Two are prominent among those descriptors: Shannon's entropy and Statistical Complexity; together, they define the ``Entropy-Entropy Plane'' (HC). 
		This work fills gaps in our previous understanding about this tool, namely:
		(i)~the lack of statistical tests, and 
		(ii)~the ambiguity in the symbols caused by the lack of information on the element's amplitude.
		We propose two solutions: a modification in the transition graph of ordinal patterns, the Weighted Amplitude Transition Graph, which weights its edges using amplitude variation information between the symbols, and HC-PCA, a computing method an empirical test on the HC plane.
		Were developed applications in the context of remote sensing and analysis of white noise sequences. 
		
		\noindent
		{\bf Keywords}. Bandt-Pompe Symbolization, Ordinal Patterns, Entropy-Complexity Plane, Information theory, Time Series, Image Analysis
	\end{abstract}
	
	\section{Introduction}
	
	Data mining applications use highly diverse massive volumes of information.
	With this, the complexity of the investigations, its interdisciplinarity, and the number of required features also increased.
	Thus, the study of simple approaches which are computationally affordable and independent of the type of data has become fundamental.
	
	According to the Web of Science, the Bandt-Pompe methodology and its variants have been used successfully in the analysis of many types of dynamics, receiving so far more than \num{2600} citations.
	Works using this approach span several areas such as:
	The study of electroencephalography signals using wavelet decomposition~\cite{baravalle2018discriminating};
	analysis and characterization of economic time series, e.g., stock market, sovereign bonds, credit rating, commodities, and cryptocurrencies~\cite{Araujo2019permutation}.
	
	The Bandt-Pompe methodology consists of mapping a time series onto a point in a closed $\mathbbm R^2$ manifold: the Complexity-Entropy plane.
	Two points are well-known in this plane:
	\begin{enumerate}
		\item \textbf{White noise}, that is, random sequences with no temporal structure, where the entropy presents its maximum value while the complexity is minimal; and
		\item \textbf{Deterministic data}, that is, sequences with a periodic structure, where entropy and statistical complexity have their minimum values.
	\end{enumerate}
	
	This dissertation advances the state-of-the-art in this field by investigating three of the leading open problems: 
	(i)~the application of the Bandt-Pompe approach in image analysis,
	(ii)~the lack of amplitude weighting methods in transition graphs of ordinal patterns, and 
	(iii)~the lack of test statistics.
	By proposing an expansion of the applicability of Bandt-Pompe to images, we present a new methodology for extracting texture characteristics from SAR (Synthetic Aperture Radar) images.
	
	\section{Bandt-Pompe Symbolization}\label{BP}
	
	Consider ${\mathcal X} = \{x_t\}_{t=1}^{T}$, a real valued time series of length $T$. 
	Let ${\mathfrak A}_{D}$ (with $D \geq 2$ and $D \in {\mathbb  N}$) be the symmetric group of order $D!$ formed by all 
	possible permutations of order $D$, and the symbols  vector 
	${\bm \pi}^{(D)} = (\pi_1, \pi_2, \dots, \pi_D)$, so every element ${\bm \pi}^{(D)}$ is unique 
	($\pi_j \neq \pi_k$ for every $j \neq k$). 
	The time delay embedding representation of ${\mathcal X}$
	with embedding dimension $D \geq 2$ and time delay $\tau \geq 1$ ($\tau \in {\mathbb  N}$, also called ``embedding time,'' ``time delay'', or ``delay'') is:
	\begin{equation} 
		{\mathbf X}^{(D,\tau)}_t =( x_t,x_{t+\tau},\dots,x_{t+(D-1)\tau} ) ,
		\label{eq:time-delay}
	\end{equation} 
	for $t = 1,2,\dots,N$ with $N = T-(D-1) \tau$.
	Then, the vector ${\mathbf X}^{(D,\tau)}_t$ can be mapped onto a symbol vector ${\bm \pi}_t^D \in {\mathfrak A}_{D}$. 
	This mapping preserves the order relationships between the elements 
	$x_t  \in {\mathbf X}^{(D,\tau)}_t$, and all $t \in \{1,\dots,T-(D-1)\tau\}$ that share this pattern (also called ``motif'') are mapped onto the same 
	${\bm \pi}_t^{D}$.
	We define the mapping ${\mathbf X}_t^{(D,\tau)} \mapsto {\mathbf \pi}_t^{D}$ by ordering the observations $x_t \in {\mathbf X}_t^{(D,\tau)}$ in increasing order.
	
	The classic approach to calculating the probability distribution of ordinal patterns is through the frequency histogram.
	Denote $\Pi$ the sequence of symbols obtained from the series $\mathbf{X}_t^{(D,\tau)}$.
	The Bandt-Pompe probability distribution is the relative frequency of symbols in the series against the $D!$ possible patterns $\{\widetilde\pi_t^D \}_{t = 1}^{D!}$:
	\begin{equation}
		p(\widetilde\pi_t^D) = \frac{\#\left \{\mathbf{X}_t^{(D,\tau)} \text{ is of type } \widetilde\pi_t^D\right \}}{T- (D-1)\tau},  
	\end{equation}
	where  $t\in \{1, \dots, T-(D-1)\tau\}$.
	These probabilities meet the conditions $p(\widetilde\pi_t^D) \ge 0$ and  $\sum_{i=1}^{D!} p(\widetilde\pi_t^D) = 1$, are invariant before monotonic transformations of the time series values, and, being based on order statistics, are robust to contamination.
	
	\section{Information-Theoretic Descriptors}\label{HC}
	
	After computing all the symbols and their probabilities, the next step into the characterization of the time series is computing descriptors.
	Entropy measures the disorder or unpredictability of a system, and its normalized version is:	
	\begin{equation}
		H(\mathbbm{P}) = - \frac{1}{\log D!}\sum_{\ell = 1}^{D!} p_\ell \log p_\ell,
		\label{eq:Entropia}
	\end{equation}
	where $p_\ell$ is the probability obtained from the symbolization.
	Although very expressive, the Shannon Entropy is not able to describe all possible underlying dynamics.
	To this aim, L\'opez-Ruiz et al.~\cite{LopezRuiz1995} proposed using the disequilibrium  $Q$, a measure of how far $\mathbbm{P}$ is from an equilibrium or non-informative distribution $\mathbbm{U}$, e.g., the uniform law.
	We calculate this descriptor as:
	\begin{equation}
		Q'(\mathbbm{P}, \mathbbm{U}) = \sum_{\ell=1}^{D!} \Big(p_\ell \log\frac{p_\ell}{u_\ell} +
		u_\ell \log\frac{u_\ell}{p_\ell}
		\Big),
	\end{equation}
	and then we normalize it $Q = Q'/\max\{Q'\}$.
	With this, the Statistical Complexity which measures the dependence structures among the elements is $C = HQ$.
	We can then map a time series onto the point $(h, c)$, and the set of all possible points is the Entropy-Complexity plane $H \times C$.
	
	% New section
	\section{SAR Texture Classification with Weighted Amplitude Transition Graphs}\label{WATG}
	
	We proposed a technique for texture analysis and classification based on the Bandt-Pompe symbolization for Synthetic Aperture Radar -- SAR data.
	It consists of
	(i)~linearize a \mbox{2-D} patch of the image using a Hilbert-Peano curve,
	(ii)~build an Ordinal Pattern Transition Graph that considers the data amplitude encoded into the weight of the edges;
	(iii)~obtain a probability function derived from this graph;
	(iv)~compute Information Theory descriptors (Permutation Entropy and Statistical Complexity) from this distribution and use them as features to feed a classifier.
	
	Our proposal, hereinafter referred to as Weighted Amplitude Transition Graph (WATG), differs from the traditional ordinal pattern transition graph by incorporating the absolute difference between successive patterns. 
	First, each time series $\mathcal{X}$ is scaled to $[0, 1]$, since we are interested in a metric able to compare datasets:
	\begin{equation}
		\frac{x_i - x_{\min}}{x_{\max} - x_{\min}} \longmapsto x_i,
		\label{eq:scaling}
	\end{equation}
	where $x_{\min}$ and $x_{\max}$ are, respectively, the minimum and maximum values of the series.
	This transformation is relatively stable before contamination, e.g., if instead of $x_{\max}$ we observe $k x_{\max}$ with $k\geq 1$, the relative values are not altered. 
	Nevertheless, other more resistant transformations as, for instance, $z$ scores, might be considered.
	
	Each $\mathbf{X}^{(D, \tau)}_t$ vector is associated with a weight $\beta_t$ that measures the largest difference between its elements:
	\begin{equation}
		\beta_t = \max\{|x_i - x_j|\},
	\end{equation}
	where $x_i, x_j \in \mathbf{X}^{(D, \tau)}_t$.
	We propose that the weight assigned to each edge is proportional to the amplitude difference observed in the transition:	
	\begin{equation}
		w_{v_{\widetilde \pi^D_i}, v_{\widetilde \pi^D_j}} =  \sum_{i : \{\mathbf{X}^{(D,\tau)}_t \mapsto \widetilde\pi^D_i\}} \sum_{j : \{\mathbf{X}^{(D,\tau)}_t \mapsto \widetilde\pi^D_j\}} |\beta_i - \beta_j| .
	\end{equation}
	Thus, the probability distribution taken from the weighted amplitude transition graph is:	
	\begin{align}
		&\left\{\begin{array}{l}
			\lambda_{v_{\widetilde\pi^D_i}, v_{\widetilde\pi^D_j}} = 1, \text{ if } (v_{\widetilde\pi^D_i}, v_{\widetilde\pi^D_j}) \in {E}, \\
			\lambda_{v_{\widetilde\pi^D_i}, v_{\widetilde\pi^D_j}} = 0, \text{ otherwise}.
		\end{array}\right., \text{ and} \\
		&p(\widetilde\pi^D_i, \widetilde\pi^D_j) = \frac{\lambda_{v_{\widetilde\pi^D_i}, v_{\widetilde\pi^D_j}} \cdot w_{v_{\widetilde\pi^D_i}, v_{\widetilde\pi^D_j}}}{\sum_{v_{\widetilde\pi^D_a}, v_{\widetilde\pi^D_b}} w_{v_{\widetilde\pi^D_a}, v_{\widetilde\pi^D_b}}}.
	\end{align}
	Note that  $p(\widetilde\pi^D_i, \widetilde\pi^D_j) \ge 0$ and $\sum_{\widetilde\pi^D_i, \widetilde\pi^D_j} p(\widetilde\pi^D_i, \widetilde\pi^D_j) = 1$, so $p$ is a probability function.
	
	We highlight the impact of the weighting on the probability distribution in the two extreme cases observed:
	\begin{itemize}
		\item If the \mbox{1-D} signal has low amplitude variations and peaks, then the transitions of ordinal patterns that represent the latter have large weights.
		This contributes so that the symbols' probability distribution becomes less uniform since it will be more concentrated in these edges.
		This will also cause a drop in entropy when compared to the traditional method.
		\item If the \mbox{1-D} signal has uniform amplitude variation, the weights are well distributed between the edges, giving rise to a more uniform distribution, thus with large entropy.
	\end{itemize}
	
	To validate our technique in a remote sensing application, we manually selected $200$ samples from JPL's Uninhabited Aerial Vehicle SAR (UAVSAR) images patches of size $128 \times 128$ to compose the dataset used in the experiments:
	$40$ samples from Guatemalan forests;
	$40$ samples from Guatemalan pasture regions;
	$80$ samples from oceanic regions of Cape Canaveral, divided into two types with different contrast; and
	$40$ samples of urban regions of the city of Munich.
	
	Experiments with the $k$-nearest neighbor algorithm with Euclidean distance applied to the pairs Entropy-Statistical Complexity descriptors showed that our proposal performs better than Grey-Level Co-occurrence Matrices, Bandt-Pompe, Transition Graphs, SURF (Speeded-Up Robust Features), \mbox{STFT + SURF} (Short-Time Fourier Transform), and other techniques which also employ amplitude information in the analysis of ordinal patterns, and provides the same quality of results obtained with Gabor filters and HOG (Histograms of Oriented Gradients).
	However, while Gabor filters employ $80$ features and HOG uses $54$ features, our proposal requires only two.
	This dimensionality reduction is a huge advantage over the other techniques, with added values:
	Firstly, by reducing the dimension of the features to \mbox{2-D}, we can visualize the results.
	Secondly, for machine learning algorithms, the smaller the number of dimensions is, the faster the training process is, and the less storage space is required.
	Thirdly, overfitting, a recurring problem in data of high dimensionality, is avoided.
	Table~\ref{tab:result1} is a summary of the results presented in Ref.~\cite{AnalysisandClassificationofSARTexturesUsingInformationTheory}.
	
	
	We also observed that only one feature ($H$ or $C$) is enough to discriminate the classes with the same reported performance. 
	We opted to preserve both features because we consider that this study shed light on a novel way of analyzing SAR images. 
	
	\begin{table*}
		\centering
		\caption{Experimental results using $k$-NN}
		\label{tab:result1}
		\resizebox{15cm}{!}{
			\begin{tabular}{lrrrr*9{r}}
				\toprule
				\multirow{2}{*}{Method} & \multirow{2}{*}{\# features} & & TPR & & & & PPV & & & \multirow{2}{*}{AA} & \multirow{2}{*}{$\text{F1-Score}_{\mu}$} & \multirow{2}{*}{$\text{F1-Score}_M$} \\ 
				\cmidrule(lr){3-6} 
				\cmidrule(lr){7-10}
				&   & Forest & Pasture & Ocean & Urban & Forest & Pasture & Ocean & Urban & &  \\ 
				\cmidrule(lr){1-1}
				\cmidrule(lr){2-2}
				\cmidrule(lr){3-6}
				\cmidrule(lr){7-10}
				\cmidrule(lr){11-11}
				\cmidrule(lr){12-12}
				\cmidrule(lr){13-13}
				Gabor & 80 & 
				1.000 & 1.000 & 1.000 & 1.000 & 
				1.000 & 1.000 & 1.000 & 1.000 & 
				1.000 & 1.000 & 1.000\\
				HOG & 54 & 
				1.000 & 1.000 & 1.000 & 1.000 & 
				1.000 & 1.000 & 1.000 & 1.000 & 
				1.000 & 1.000 & 1.000\\
				GLCM & 32 & 
				0.833 & 1.000 & 1.000 & 0.833 &
				1.000 & 0.857 & 0.923 & 1.000 &
				0.967 & 0.980 & 0.970\\
				SURF & 1856 & 
				0.500 & 0.000 & 1.000 & 0.000 & 
				1.000 & 0.000 & 0.444 & 0.000 &
				0.467 & 0.666 & 0.572\\
				STFT + SURF  & 1856 & 
				0.166 & 0.000 & 0.833 & 0.166 & 
				0.250 & 0.000 & 0.416 & 0.500 &
				0.300 & 0.462 & 0.292\\
				\cmidrule(lr){1-1}
				\cmidrule(lr){2-2}
				\cmidrule(lr){3-6}
				\cmidrule(lr){7-10}
				\cmidrule(lr){11-11}
				\cmidrule(lr){12-12}
				\cmidrule(lr){13-13}
				Bandt-Pompe & 2 & 
				0.333 & 1.000 & 0.750 & 1.000 &
				0.500 & 0.857 & 0.750 & 0.857 &
				0.600 & 0.776 & 0.633\\ 
				Transition Graph & 2 & 
				0.833 & 0.666 & 0.833 & 1.000 &
				0.833 & 0.800 & 0.769 & 1.000 &
				0.767 & 0.929 & 0.875\\
				\cmidrule(lr){1-1}
				\cmidrule(lr){2-2}
				\cmidrule(lr){3-6}
				\cmidrule(lr){7-10}
				\cmidrule(lr){11-11}
				\cmidrule(lr){12-12}
				\cmidrule(lr){13-13}
				WPE & 2 & 
				1.000 & 0.833 & 1.000 & 0.833 &
				0.857 & 0.833 & 1.000 & 1.000 &
				0.933 & 0.868 & 0.779\\ 
				AAPE & 2 & 
				0.666 & 1.000 & 1.000 & 1.000 &
				1.000 & 0.857 & 0.923 & 1.000 &
				0.833 & 0.947 & 0.896\\ 
				FGPE & 2 & 
				0.666 & 0.666 & 1.000 & 1.000 &
				0.800 & 0.666 & 0.923 & 1.000 &
				0.767 & 0.868 & 0.711\\ 
				\cmidrule(lr){1-1}
				\cmidrule(lr){2-2}
				\cmidrule(lr){3-6}
				\cmidrule(lr){7-10}
				\cmidrule(lr){11-11}
				\cmidrule(lr){12-12}
				\cmidrule(lr){13-13}
				WATG & 2 & 
				1.000 & 1.000 & 1.000 & 1.000 &
				1.000 & 1.000 & 1.000 & 1.000 &
				1.000 & 1.000 & 1.000\\
				\bottomrule
			\end{tabular}
		}
	\end{table*}
	
	\section{A Test for White Noise in the Entropy-Complexity Plane}\label{HC-PCA}
	
	We propose the first approach that uses the entropy-complexity plane to test the white noise hypothesis by finding a latent space representative of the data without the restrictions of the plane's boundaries.
	Through this new representation of the data, we calculate empirical regions with different levels of confidence.
	Finally, after calculating these regions, we build a test statistic that determines the probability that a given sequence belongs to the distribution of the points provided.
	
	Our test is based on two sources of true random numbers, both from the observation and measurement of physical phenomena.
	The first uses vacuum states~\cite{RNGVacuumStates}, and the second one employs atmospheric noise captured by a cheap radio receiver with no filter for unwanted static sounds caused by atmospheric noise~\cite{RandomOrg}.
	We used \SI{54e6}{4\byte} words from each physical generator, which approximately amounts \SI{200}{\mega\byte} of data.
	
	The first step of the proposed technique consists in finding and applying the principal components transformation to $\utilde{hc}$.
	With this, we obtain the set of uncorrelated points 
	$$\utilde{uv}=\big((u_1,v_1), (u_2,v_2),\dots,(u_N,v_N)\big),$$ 
	in which $u_n$ and $v_n$ are the first and second principal components of $h_n$ and $v_n$, respectively.
	This projection allows us to obtain a ``central'' point of the data set, around which we will build a rectangular box containing \SI{100}{\minusalphapercent} of the observations.
	Such box is a variation of the bagplot \cite{TheBagplotaBivariateBoxplot}.
	Notice that finding the smallest box that encloses $k$ out of $N$ points is difficult; cf.\ the work by Chan et al. (2020)~\cite{SmallestKEnclosingRectangleRevisited}.
	For simplicity, and without loss of generality, assume $N$ is odd.
	\begin{enumerate}
		\item Find the indexes that sort the values of the first principal component $\bm u=(u_1,u_2,\dots,u_N)$ in ascending order: $\bm r=(r_1,r_2,\dots,r_N)$, i.e., $u_{r_1}$ is the minimum value, and $u_{r_N}$ is the maximum value.
		\item\label{item:Median} Find the point $(u,v)$ whose first principal component is the median: $(u_{r_{(N+1)/2}}, \cdot)$. Apply the inverse principal components transformation, and obtain $\bm P'=(h',v')$. Call the corresponding time series ``emblematic time series.''
		\item\label{item:Point1} Find the point $(u,v)$ whose first principal component is the quantile $\alpha/2$: $(u_{r_{[N\alpha/2]}}, \cdot)$.
		\item\label{item:Point2} Find the point $(u,v)$ whose first principal component is the quantile $1-\alpha/2$: $(u_{r_{[N(1-\alpha/2)]}}, \cdot)$.
		\item\label{item:Point3} The values $u_{r_{[N\alpha/2]}}$ and $u_{r_{[N(1-\alpha/2)]}}$ are the rightmost and leftmost bounds of the box, respectively.
		\item\label{item:Point4} The bottom bound of the box is the smallest second principal component value whose first principal component is at least $u_{r_{[N\alpha/2]}}$; denote this values $v_{\min}$.
		\item\label{item:Point5} The top bound of the box is the largest second principal value whose first principal component is at most $u_{r_{[N(1-\alpha/2)]}}$; denote this value $v_{\max}$.
		\item The corners of the box are 
		$(u_{r_{[N\alpha/2]}}, v_{\min})$, 
		$(u_{r_{[N\alpha/2]}}, v_{\max})$, 
		$(u_{r_{[N(1-\alpha/2)]}}, v_{\min})$ and 
		$(u_{r_{[N(1-\alpha/2)]}},v_{\max})$.
		\item\label{item:BoxHxC} Apply the inverse principal components transformation to these corners obtaining $\bm P_1=(h_{v_1}, c_{v_1})$, $\bm P_2=(h_{v_2},h_{v_2})$, $\bm P_3=(h_{v_3}, c_{v_3})$ and $\bm P_4=(h_{v_4},c_{v_4})$.
	\end{enumerate}
	
	These confidence regions obtained provide a powerful tool to make binary assessments about the adequacy of a given time series $\bm X$ to the null hypothesis $\mathcal H_0$ that it is white noise.
	More generally, we are interested in obtaining the $p$-value of $\bm x$ under $\mathcal H_0$.
	We present a procedure to obtain an approximate $p$-value based on the evidence collected to build the confidence regions.
	
	The procedure operates on the principal components space and consists of measuring the closeness between the ``emblematic point'' and the observed point.
	We are given a time series $\bm X$ of size $T$, and we want its $p$-value when contrasted with TWNRS of the same size at embedding dimension $D$.
	We use $N$ TWNRS of size $T$, compute their points in the $H\times C$ plane, and project them to the corresponding principal components space.
	We then do the same with $\bm x$, and obtain a new point $(u_x,v_x)$.
	The closer $\bm x$ is to the emblematic time series, the larger its $p$-value.
	Assume that the emblematic time series is represented by $(u,v)$ in the principal components space.
	We measure this closeness by building a box around $(u_x,v_x)$ that contains $(u,v)$; assume that $u_x>u$, then:
	\begin{enumerate}
		\item the right side of the box is the smallest $u_j$ which is larger that $u_x$; assume it corresponds to the quantile $\eta_u$ of $\utilde u = (u_1,u_2,\dots, u_N)$. By definition, $\eta_u\geq 1/2$.
		%
		\item the left side of the box is the $1-\eta_u$ quantile of $\utilde u$.
		%
		\item the top side of the box is the smallest $v_j$ which is larger that $v_x$; assume it corresponds to the quantile $\eta_v$ of $\utilde v = (v_1,v_2,\dots, v_N)$. By definition, $\eta_v\geq 1/2$.
		%
		\item the bottom side of the box is the $1-\eta_v$ quantile of $\utilde v$.
	\end{enumerate}
	
	The definition of the box for the case $u_x<u$ follows naturally.
	With this approach, we obtain the smallest box that (i)~contains the new point, and (ii)~is defined by observed points from TRWNS.
	Such boxes are less prone to distortions in this space since the distribution of the points becomes less asymmetric than in the $H\times C$ plane.
	
	We conducted an ablation study to identify the influence of the parameters $T$, $D$, and $\tau$ in the construction of empirical confidence regions.
	We verified that the results involving the time delay parameter variation did not show significant differences in repeated experiments; therefore, in the sequel, we did no consider $\tau$ as a determining factor.
	On the other hand, we found two relevant variables: the length of the sequence and the embedding dimension.
	We, thus, employed the following factors:
	\begin{itemize}
		\item Sequence length $T\in\mathcal T=\{ \num[scientific-notation=true]{e3}, \num[scientific-notation=true]{5 e4}\}$,
		\item Embedding dimension $D\in\mathcal D=\{3, 4, 5, 6\}$.
	\end{itemize}
	and kept $\tau=1$, which is the most frequently used option.
	The values of $D$ are within the range recommended in the literature~\cite{PermutationEntropyBandtPompe}.
	
	Our test has a good size, mostly with long TWNRS.
	We also determined the power of our test for the alternative hypothesis of correlated $f^{-k}$ noise and found that it rejects the null hypothesis ($k=0$) for $k>3/10$.
	
	Although our work focuses on the study of short sequences, we were able to capture the random behavior of well-known pseudorandom number generators already analyzed in the literature. 
	With this, we verified the adequacy of our technique as it is capable of detecting correlation structures.
	
	\section{Conclusions} 
	
	The main objective of this work was the investigation of problems present in the methodology of symbolization of Bandt-Pompe and its applicability in the characterization of time series and images.
	Interested in expanding the range of possible applications, we focus on investigating properties of transition graphs and their possible limitations present in the state of the art.
	Another objective was the study of the joint distribution obtained by the descriptors of the Complexity-Entropy plane, as well as possible linear transformations in this space.
	Thus, we have advanced in the state of the art by proposing some solutions to deal with scenarios not foreseen in the seminal article by Bandt-Pompe. 
	
	\section*{Acknowledgements}
	
	This work was partially funded by the Coordination for the Improvement of Higher Education Personnel (CAPES) and National Council for Scientific and Technological Development (CNPq).
	
	\begin{thebibliography}{00}
		
		\bibitem{Araujo2019permutation} Araujo, F. H. A., Bejan, L., Rosso, O. A and Stosic, T. 
		Permutation entropy and statistical complexity analysis of Brazilian agricultural commodities, 
		{\it Entropy}, 
		volume 21, 
		page 1220,
		2019. 
		DOI: 10.3390/e21121220.
		
		\bibitem{PermutationEntropyBandtPompe} Bandt, C. and Pompe, B.
		Permutation Entropy: A Natural Complexity Measure for Time Series,
		{\it Physical Review Letters}, 
		volume 88, 
		pages 174102-1--174102-4,
		2002.
		DOI: 10.1103/PhysRevLett.88.174102.
		
		\bibitem{baravalle2018discriminating} Baravalle, R., Rosso, O. A., and Montani, F. 
		Discriminating imagined and non-imagined tasks in the motor cortex area: Entropy-complexity plane with a wavelet decomposition, 
		{\it Physica A: Statistical Mechanics and its Applications}, 
		volume 511, 
		pages 27--39,
		2018. 
		DOI: 10.1016/j.physa.2018.07.038.
		
		\bibitem{AnalysisandClassificationofSARTexturesUsingInformationTheory}
		Chagas, E. , Frery, A. C. , Rosso, O. A., and Ramos, H. S., Analysis and Classification of SAR Textures using Information Theory, \textit{IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, vol. 14, pages 663--675, 2021, DOI: 10.1109/JSTARS.2020.3031918.
		
		
		\bibitem{SmallestKEnclosingRectangleRevisited} Chan, T. M. and Har-Peled, S.
		Smallest k-Enclosing Rectangle Revisited,
		{\it Discrete {\&} Computational Geometry},
		2020. 
		DOI: 10.1007/s00454-020-00239-3.
		
		\bibitem{ABadgingSystemforReproducibilityandReplicabilityinRemoteSensingResearch} Frery, A. C., and Gomez, L. and A. C. Medeiros.
		A Badging System for Reproducibility and Replicability in Remote Sensing Research,
		{\it IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens.}, 
		volume 13, 
		pages 4988--4995,
		2020.
		DOI: 10.1109/JSTARS.2020.3019418.
		
		\bibitem{RNGVacuumStates} Gabriel, C., Wittmann, C., Sych, D., Dong, R., Mauerer, W., Andersen, U. L., Marquardt, C. and Leuchs, G.
		A generator for unique quantum random numbers based on vacuum states,
		{\it Nature Photonics}, 
		volume 4, 
		pages 711--715,
		2010. 
		DOI: 10.1038/nphoton.2010.197.
		
		%REVISAR
		\bibitem{RandomOrg} Haahr, M.
		RANDOM.ORG: True Random Number Service,
		{\it \url{https://www.random.org}}, 
		1998--2018. 
		Accessed: 2018-06-01.
		
		\bibitem{LopezRuiz1995} L\'opez-Ruiz, R., Mancini, H. L., and Calbet, X.
		A statistical measure of complexity, 
		{\it Physics Letters A}, 
		volume 209, 
		pages 321--326,
		1995. 
		DOI: 10.1016/0375-9601(95)00867-5.
		
		\bibitem{TheBagplotaBivariateBoxplot} Rousseeuw, P. J., Ruts, I., and Tukey, J. W.
		The Bagplot: A Bivariate Boxplot,
		{\it The American Statistician}, 
		volume 53, 
		page 382,
		1999. 
		DOI: 10.2307/2686061.
		
	\end{thebibliography}
	
\end{document}

%As equações são numeradas sequencialmente no texto, com a numeração automaticamente colocada à direita (favor não alterar) usando o comando \verb!\label{nome-da-equacao}! para identificá-las. A chamada \verb!\eqref{nome-da-equacao}! faz referência à equação, no texto. 
