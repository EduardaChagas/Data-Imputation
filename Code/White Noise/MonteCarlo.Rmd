---
title: "Monte Carlo study"
author: "Eduarda Chagas"
date: "Nov 10, 2020"
bibliography: ['../sbc-template.bib']
output: html_notebook
---

### Load packages and sources

```{r}
source("testPoint.R")
source("Bandt-Pompe.R")
if(!require(foreach)){
  install.packages("foreach")
  require(foreach)
} 
```

The purpose of the study is measuring the ability of imputation methods (Data-driven and Time ordered imputation) to retrieve the underlying dynamic of a time series that has been *attacked*.
In a loose sense, we will assess the *breakdown point* of the imputation techniques (study references for "breakdown point") [@donoho1983notion; @yohai1987high].
The **attack** consists in introducing randomly repeated values in the sequence.

### Reading white noise data
```{r}
white.noise.samples <- function(N){
  filenames = list.files(path = "../../../../random.org/")
  names = substr(filenames, 1, 10)
  j = 0
  dados = vector()
  for(i in names){
    j = j + 1
    filepath = file.path(paste("../../../../random.org/", i,".bin",sep=""))
    assign("Data", readBin(filepath, n = 1e8, size = "4", what ='integer'))
    dados = c(dados, Data)
  }
  dados = abs(dados/max(dados))
  n.series = round((length(dados)/N), digits = 0)
  cat(n.series, ' time series were formed\n')
  split_seq = matrix(nrow = n.series, ncol = N)
  for(i in 1:n.series){
    split_seq[i,] = dados[sample(1:length(dados), N, replace = F)]
  }
  write.csv(split_seq, file = paste0("../Data/random_sampleN", N, ".csv"))
  return(split_seq)
}
```

### Define imputation techniques as functions: Data-driven and Time ordered

### Define attack
```{r}
set.seed(123)
AttackElement <- function(e, d, p){
  if(runif(1) <= p){
      i = round(runif(1, max = d, min = 1), digits = 0)
      j = i
      while(j == i){
        j = round(runif(1, max = d, min = 1), digits = 0)
      }
      e[j] = e[i] 
  }
  return(e)
}

AttackTimeSeries <- function(time_series, d, tau, p) {
  elements = formationPattern(time_series, d, tau, 1)
  attacked_elements = apply(elements, 1, AttackElement, d, p)
  return(attacked_elements)
}
```


```{r}
tau = 1
region = 95
N = c(1000, 50000) # lengths of the time series to be considered
D = c(3, 4, 5, 6) # embedding dimensions to be considered
P = c(0.1, 0.3, 0.5, 0.7) # probabilities of attack to be considered

# Store all the points in the HxC plane of the following loop
for(n in N){
  for(d in D) {
    for(p in P) {
      cat("N: ", n, " D: ", d, " P: ", p, "\n")
      x = white.noise.samples(n)
      hcx = hc.samples(x, d, tau)
      x_attack = AttackTimeSeries(x, d, tau, p)
      
      hc_x_timeordered = hc.time.ordered.samples(x_attack, d, tau)
      hc_x_datadriven = hc.data.driven.samples(x_attack, d, tau)
      
      test_timeordered = test.set.point(hc_x_timeordered, d, n, region)
      cat("Time Ordered: Points inside the regions of", region, "%: ", 
          (length(test_timeordered[test_timeordered == 1])/length(test_timeordered))*100, '%\n')
      
      test_datadriven = test.set.point(hc_x_datadriven, d, n, region)
      cat("Data-driven: Points inside the regions of", region, "%: ", 
          (length(test_datadriven[test_datadriven == 1])/length(test_datadriven))*100, '%\n\n')
    }
  }
}
```

  ```{r PSEUDOCODE, eval=FALSE}
  # Define the parameter space of the Monte Carlo study
  # My suggestion: white noise, for which we already have confidence intervals in the HxC plane

# Store all the points in the HxC plane of the following loop
for(n in N){
  for(d in D) {
    for(p in P) {
      
      x <- white_noise_length_n # perhaps from the true noise we already have
      hcx <- point_in_the_HC_plane(x)
      x_attack <- AttackTimeSeries(x, d, p)
      hcxattack <- point_in_the_HC_plane(x_attack)
      
    }
  }
}

# Analyze the points, for instance:
# Measure distances between pairs
# Count the number of points inside the confidence regions
```

